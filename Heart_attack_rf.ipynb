{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1c2c6d2-dddb-4264-9271-e31a6afb3a26",
   "metadata": {},
   "source": [
    "# Heart attack prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "985aee30-ce8d-4a0d-8811-5967a19401ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3f1f11a-4cc2-4dac-93d9-3795e923c073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERSDOC3</th>\n",
       "      <th>_CHLDCNT</th>\n",
       "      <th>_URBSTAT</th>\n",
       "      <th>_CURECI2</th>\n",
       "      <th>_RACEG22</th>\n",
       "      <th>CHCKDNY2</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>DIFFWALK</th>\n",
       "      <th>_SMOKER3</th>\n",
       "      <th>_MENT14D</th>\n",
       "      <th>...</th>\n",
       "      <th>ASTHMA3</th>\n",
       "      <th>DIFFALON</th>\n",
       "      <th>EDUCA</th>\n",
       "      <th>_HCVU652</th>\n",
       "      <th>DECIDE</th>\n",
       "      <th>WTKG3</th>\n",
       "      <th>CHCCOPD3</th>\n",
       "      <th>RENTHOM1</th>\n",
       "      <th>_SMOKGRP</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5670.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13154.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10886.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10659.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5398.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PERSDOC3  _CHLDCNT  _URBSTAT  _CURECI2  _RACEG22  CHCKDNY2  MARITAL  \\\n",
       "0       2.0       1.0       1.0       1.0       1.0       2.0      3.0   \n",
       "1       1.0       2.0       1.0       1.0       1.0       2.0      2.0   \n",
       "2       1.0       1.0       1.0       1.0       1.0       2.0      1.0   \n",
       "3       1.0       1.0       1.0       1.0       1.0       2.0      1.0   \n",
       "4       2.0       1.0       1.0       1.0       1.0       2.0      4.0   \n",
       "\n",
       "   DIFFWALK  _SMOKER3  _MENT14D  ...  ASTHMA3  DIFFALON  EDUCA  _HCVU652  \\\n",
       "0       2.0       4.0       2.0  ...      2.0       2.0    6.0       9.0   \n",
       "1       1.0       1.0       3.0  ...      2.0       2.0    5.0       1.0   \n",
       "2       2.0       4.0       1.0  ...      2.0       2.0    5.0       1.0   \n",
       "3       2.0       3.0       1.0  ...      2.0       2.0    4.0       1.0   \n",
       "4       2.0       1.0       2.0  ...      2.0       2.0    4.0       1.0   \n",
       "\n",
       "   DECIDE    WTKG3  CHCCOPD3  RENTHOM1  _SMOKGRP  TARGET  \n",
       "0     1.0   5670.0       2.0       1.0       4.0   False  \n",
       "1     1.0  13154.0       2.0       2.0       1.0   False  \n",
       "2     2.0  10886.0       2.0       1.0       4.0   False  \n",
       "3     2.0  10659.0       1.0       1.0       2.0   False  \n",
       "4     2.0   5398.0       2.0       3.0       1.0   False  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Charger le fichier train.parquet\n",
    "ex = pd.read_parquet('data/extra.parquet')\n",
    "train = pd.read_parquet('data/train.parquet')\n",
    "\n",
    "train_data = pd.concat([ex, train])\n",
    "\n",
    "# Colonnes d'intérêt\n",
    "columns = ['PERSDOC3', '_CHLDCNT', '_URBSTAT', '_CURECI2', '_RACEG22', 'CHCKDNY2', 'MARITAL', 'DIFFWALK', '_SMOKER3', '_MENT14D', 'USENOW3',\n",
    "           '_IMPRACE', 'CHECKUP1', 'CHCOCNC1', '_LTASTH1', 'GENHLTH', 'SEXVAR', 'HIVTST7', 'RMVTETH4', '_LLCPWT', '_AGEG5YR', 'HIVRISK5',\n",
    "           '_RACE1', 'WEIGHT2', 'DRNKANY6', '_PHYS14D', '_DENVST3', 'EMPLOY1', '_METSTAT', 'CVDSTRK3', '_STATE', 'ADDEPEV3', 'HAVARTH4',\n",
    "           'ALCDAY4', 'MENTHLTH', 'CHCSCNC1', 'BLIND', '_EXTETH3', '_LLCPWT2', '_STRWT', 'TETANUS1', 'CHILDREN', 'DIFFDRES', 'SMOKE100',\n",
    "           '_PRACE2', 'FLUSHOT7', 'DIABETE4', 'VETERAN3', 'SEQNO', '_RFSMOK3', 'PHYSHLTH', 'HTIN4', '_RAWRAKE', 'MEDCOST1', 'LASTDEN4',\n",
    "           '_HISPANC', '_RFBMI5', '_DRDXAR2', 'PRIMINSR', 'LCSCTSC1', '_ASTHMS1', 'EXERANY2', '_BMI5CAT', 'QSTVER', '_CASTHM1', 'PNEUVAC4',\n",
    "           'COVIDPOS', '_BMI5', '_DUALUSE', 'INCOME3', '_RFHLTH', 'HEIGHT3', 'ECIGNOW2', 'SLEPTIM1', 'DEAF', '_HLTHPLN', '_INCOMG1', 'CPDEMO1C',\n",
    "           'QSTLANG', 'ASTHMA3', 'DIFFALON', 'EDUCA', '_HCVU652', 'DECIDE', 'WTKG3', 'CHCCOPD3', 'RENTHOM1', '_SMOKGRP', 'TARGET']\n",
    "           \n",
    "\n",
    "'''\n",
    "#Identification des colonnes avec le plus de valeurs manquantes\n",
    "# 1. Calcul du nombre de valeurs manquantes par colonne\n",
    "dataset_explicatif=train_data.drop(columns=['TARGET', 'ID'])\n",
    "nan_counts = dataset_explicatif.isna().sum()\n",
    "# 2. Filtrer les colonnes avec au moins une valeur manquante et trier par ordre décroissant\n",
    "nan_counts_sorted = nan_counts[nan_counts > 0].sort_values(ascending=False)\n",
    "# 3. Stocker dans une nouvelle variable\n",
    "columns_with_nan = nan_counts_sorted\n",
    "columns_to_drop = columns_with_nan[columns_with_nan > 60000].index.values\n",
    "#columns_to_drop = np.append(columns_to_drop, ['FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'IYEAR'])\n",
    "'''\n",
    "\n",
    "# Extraction des colonnes\n",
    "train_data = train_data[columns] #train_data.copy() #train_data[columns] # train_data.drop(columns=columns_to_drop)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bfc03f4-26ab-44b7-b902-333902071ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Nettoyage des données : remplacer les NaN par la moyenne (ou une autre stratégie)\n",
    "train_data_cleaned = train_data.apply(lambda col: col.fillna(col.rolling(window=10, min_periods=1).median()), axis=0)\n",
    "\n",
    "# Séparer les données en variables explicatives (X) et cible (y)\n",
    "X = train_data_cleaned.drop(\"TARGET\", axis=1)\n",
    "y = train_data_cleaned[\"TARGET\"]\n",
    "\n",
    "# Diviser en ensemble d'entraînement et de validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b3368ef-12bf-4f8b-b2b1-2c3018d78085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sur l'ensemble de validation: 0.24171\n"
     ]
    }
   ],
   "source": [
    "# 3. Entraîner un modèle (XGBoost Classifier)\n",
    "# Paramètres XGBoost\n",
    "params = {\n",
    "    'booster': 'gbtree',                # Type d'algorithme booster\n",
    "    'learning_rate': 0.4,               # Taux d'apprentissage\n",
    "    'max_depth': 6,                     # Profondeur maximale des arbres\n",
    "    'min_child_weight': 1,              # Poids minimum pour les feuilles\n",
    "    'subsample': 0.8,                   # Fraction des données à utiliser pour chaque arbre\n",
    "    'colsample_bytree': 0.8,            # Fraction des caractéristiques à utiliser\n",
    "    'objective': 'binary:logistic',     # Fonction objective pour la classification binaire\n",
    "    'eval_metric': 'logloss',           # Évaluation avec logloss\n",
    "    'n_estimators': 1250,                # Nombre d'arbres\n",
    "    'gamma': 0.1,                       # Réduction de la perte nécessaire pour effectuer une division\n",
    "}\n",
    "\n",
    "# Création du modèle XGBoost\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluer le modèle sur l'ensemble de validation\n",
    "y_pred = model.predict(X_val)\n",
    "accuracy = f1_score(y_val, y_pred)\n",
    "print(f\"Accuracy sur l'ensemble de validation: {accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5396b71-f765-4917-aaa9-027f76dfd7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Charger le fichier test.parquet\n",
    "test_data = pd.read_parquet('data/test.parquet')\n",
    "\n",
    "# Conserver uniquement les colonnes d'intérêt\n",
    "columns_test = ['PERSDOC3', '_CHLDCNT', '_URBSTAT', '_CURECI2', '_RACEG22', 'CHCKDNY2', 'MARITAL', 'DIFFWALK', '_SMOKER3', '_MENT14D', 'USENOW3',\n",
    "           '_IMPRACE', 'CHECKUP1', 'CHCOCNC1', '_LTASTH1', 'GENHLTH', 'SEXVAR', 'HIVTST7', 'RMVTETH4', '_LLCPWT', '_AGEG5YR', 'HIVRISK5',\n",
    "           '_RACE1', 'WEIGHT2', 'DRNKANY6', '_PHYS14D', '_DENVST3', 'EMPLOY1', '_METSTAT', 'CVDSTRK3', '_STATE', 'ADDEPEV3', 'HAVARTH4',\n",
    "           'ALCDAY4', 'MENTHLTH', 'CHCSCNC1', 'BLIND', '_EXTETH3', '_LLCPWT2', '_STRWT', 'TETANUS1', 'CHILDREN', 'DIFFDRES', 'SMOKE100',\n",
    "           '_PRACE2', 'FLUSHOT7', 'DIABETE4', 'VETERAN3', 'SEQNO', '_RFSMOK3', 'PHYSHLTH', 'HTIN4', '_RAWRAKE', 'MEDCOST1', 'LASTDEN4',\n",
    "           '_HISPANC', '_RFBMI5', '_DRDXAR2', 'PRIMINSR', 'LCSCTSC1', '_ASTHMS1', 'EXERANY2', '_BMI5CAT', 'QSTVER', '_CASTHM1', 'PNEUVAC4',\n",
    "           'COVIDPOS', '_BMI5', '_DUALUSE', 'INCOME3', '_RFHLTH', 'HEIGHT3', 'ECIGNOW2', 'SLEPTIM1', 'DEAF', '_HLTHPLN', '_INCOMG1', 'CPDEMO1C',\n",
    "           'QSTLANG', 'ASTHMA3', 'DIFFALON', 'EDUCA', '_HCVU652', 'DECIDE', 'WTKG3', 'CHCCOPD3', 'RENTHOM1', '_SMOKGRP', 'ID']\n",
    "\n",
    "\n",
    "test_data = test_data[columns_test] #test_data.copy() #test_data[columns_test]\n",
    "\n",
    "# Nettoyer les données (remplacer les NaN)\n",
    "test_data_cleaned = test_data.drop(columns=[\"ID\"])\n",
    "test_data_cleaned = test_data_cleaned.apply(lambda col: col.fillna(col.rolling(window=10, min_periods=1).median()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "944cc3b3-30a7-4b2c-b0a4-63da4605a77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les prédictions ont été enregistrées dans le fichier prediction.csv.\n"
     ]
    }
   ],
   "source": [
    "# 5. Effectuer les prédictions\n",
    "test_predictions = model.predict(test_data_cleaned)\n",
    "\n",
    "# Ajouter les prédictions au dataframe original\n",
    "test_data[\"TARGET\"] = test_predictions\n",
    "\n",
    "# Exporter les résultats dans un fichier prediction.csv\n",
    "output_file = 'prediction.csv'\n",
    "test_data[[\"ID\", \"TARGET\"]].to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Les prédictions ont été enregistrées dans le fichier {output_file}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
